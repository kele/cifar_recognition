<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>making a tiny brain</title><link href="http://kele.github.io/cifar_recognition/" rel="alternate"></link><link href="http://kele.github.io/cifar_recognition/feeds/all.atom.xml" rel="self"></link><id>http://kele.github.io/cifar_recognition/</id><updated>2016-01-25T00:00:00+01:00</updated><entry><title>Using Lasagne to achieve over 75% accuracy on CIFAR10.</title><link href="http://kele.github.io/cifar_recognition/using-lasagne-to-achieve-over-75-accuracy-on-cifar10.html" rel="alternate"></link><updated>2016-01-25T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-01-25:cifar_recognition/using-lasagne-to-achieve-over-75-accuracy-on-cifar10.html</id><summary type="html">&lt;p&gt;This is the first report of my battle with the &lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;CIFAR10
classification&lt;/a&gt; problem.&lt;/p&gt;
&lt;p&gt;I've decided to use &lt;a href="http://lasagne.readthedocs.org/en/latest/"&gt;Lasagne&lt;/a&gt; which
is a ligthweight library build on top of
&lt;a href="http://deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's the source code I'll be talking about in this post:
&lt;a href="https://github.com/kele/cifar_recognition/tree/over75"&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;I don't do any data augmentation.&lt;/li&gt;
&lt;li&gt;This piece of code was intended to get me familiarized with Lasagne.&lt;/li&gt;
&lt;li&gt;It achieves slighly over 75% accuracy and I think it's the peak for this
  design of the neural network.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;What is in my toolbox?&lt;/h1&gt;
&lt;p&gt;My network consists of both dense and convolutional layers. There's a good
reason to use the latter, since they might exploit the nature of our problem
(which is image classification). More on that can be read
&lt;a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/"&gt;here&lt;/a&gt;,
&lt;a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/"&gt;here&lt;/a&gt; and
&lt;a href="http://neuralnetworksanddeeplearning.com/chap6.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The main intution behind convolutional layers is as follows. We want to detect a
&lt;em&gt;local&lt;/em&gt; property of an image, i.e. an edge. We don't really care (for now) where
it is, we just want to be sure that it exists. There's no difference in
detecting an edge in the middle of an image or a few pixels to the right.
Because of that, it makes no sense to keep separate parameters (weights and
biases) for different neurons, just because they're looking in some other place
for the same thing.&lt;/p&gt;
&lt;p&gt;An additional benefit is the fact that since we're sharing the parameters, there
are less of them to find.&lt;/p&gt;
&lt;h1&gt;Architecture&lt;/h1&gt;
&lt;p&gt;How does the architecture look like?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input layer&lt;/li&gt;
&lt;li&gt;2d Convolutional layer (128 filters of size 5x5, ReLu)&lt;/li&gt;
&lt;li&gt;2d MaxPool layer (pool size 2x2)&lt;/li&gt;
&lt;li&gt;2d Convolutional layer (128 filters of size 5x5, ReLu)&lt;/li&gt;
&lt;li&gt;2d MaxPool layer (pool size 2x2)&lt;/li&gt;
&lt;li&gt;Dropout layer (probability = 0.5)&lt;/li&gt;
&lt;li&gt;Dense layer (256 neurons, ReLu)&lt;/li&gt;
&lt;li&gt;Softmax layer (10 neurons)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;p&gt;With this architecture I've managed to achieve a little over 75% of accuracy
with around 2 hours of training (on my GT645&lt;strong&gt;M&lt;/strong&gt;, which is not a speed demon).&lt;/p&gt;
&lt;h1&gt;Roadmap&lt;/h1&gt;
&lt;p&gt;So, what can we do now?&lt;/p&gt;
&lt;h3&gt;Changing the network architecture&lt;/h3&gt;
&lt;p&gt;So far we can see that my network is pretty shallow. Maybe adding more filters
could help? Also, it might be helpful to put a dense ReLu layer between some
convolution layers. I'll have to experiment with these ideas.&lt;/p&gt;
&lt;h3&gt;Better learning techniques&lt;/h3&gt;
&lt;p&gt;This version of the code doesn't use &lt;strong&gt;weight decay&lt;/strong&gt; nor &lt;strong&gt;learning rate&lt;/strong&gt;
decay. The only enchancement is the &lt;strong&gt;momentum&lt;/strong&gt;. Both of the missing techniques
could be added easily.&lt;/p&gt;
&lt;p&gt;These techniques require some additional tuning, so it might be a
little time consuming to find the right parameters. It'd be a good idea to do
that as the last step, after picking a good network architecture.&lt;/p&gt;
&lt;h3&gt;Data augmentation&lt;/h3&gt;
&lt;p&gt;So far I haven't done anything with the input data at all.&lt;/p&gt;
&lt;p&gt;The following simple transformations come to my mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cropping the image at random&lt;/li&gt;
&lt;li&gt;horizontal flip&lt;/li&gt;
&lt;li&gt;rescaling&lt;/li&gt;
&lt;/ul&gt;</summary><category term="neural networks"></category><category term="cifar"></category></entry><entry><title>Getting CUDA working on a laptop with two GPUs</title><link href="http://kele.github.io/cifar_recognition/getting-cuda-working-on-a-laptop-with-two-gpus.html" rel="alternate"></link><updated>2016-01-18T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-01-18:cifar_recognition/getting-cuda-working-on-a-laptop-with-two-gpus.html</id><summary type="html">&lt;p&gt;I had a lot of trouble setting up my laptop NVIDIA GPU with CUDA on Ubuntu
14.04. These steps might actually help somebody.&lt;/p&gt;
&lt;p&gt;First, download the &lt;a href="http://developer.nvidia.com/cuda-downloads"&gt;NVIDIA CUDA Toolkit&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Remove all old NVIDIA-related drivers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-get remove --purge nvidia*
sudo apt-get --purge remove xserver-xorg-video-nouveau
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Backup your &lt;code&gt;/etc/modprobe.d/blacklist.conf&lt;/code&gt; and make sure it contains these lines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;blacklist nouveau
blacklist lbm-nouveau
blacklist nvidia-173
blacklist nvidia-96
blacklist nvidia-current
blacklist nvidia-173-updates
blacklist nvidia-96-updates
&lt;span class="nb"&gt;alias &lt;/span&gt;nvidia nvidia_current_updates
&lt;span class="nb"&gt;alias &lt;/span&gt;nouveau off
&lt;span class="nb"&gt;alias &lt;/span&gt;lbm-nouveau off
options nouveau &lt;span class="nv"&gt;modeset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Add bumblebee and xorg-edgers repositories:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-add-repository ppa:bumblebee/stable -y
sudo add-apt-repository ppa:xorg-edgers/ppa -y
sudo apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo apt-get upgrade -y
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now it's time to install the CUDA toolkit (along with &lt;code&gt;nvidia-352&lt;/code&gt; drivers).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# This installs necessary headers.&lt;/span&gt;
sudo apt-get install linux-source &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo apt-get install linux-headers-&lt;span class="k"&gt;$(&lt;/span&gt;uname -r&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# USE THE REAL PACKAGE NAME BELOW&lt;/span&gt;
sudo dpkg -i cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb

sudo apt-get install cuda
sudo apt-get update
sudo apt-get dist-upgrade -y
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Install bumblebee (to have switchable GPUs).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-get install bumblebee bumblebee-nvidia virtualgl virtualgl-libs virtualgl-libs-ia32:i386 virtualgl-libs:i386
sudo usermod -a -G bumblebee &lt;span class="nv"&gt;$USER&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Edit &lt;code&gt;/etc/bumblebee/bumblebee.conf&lt;/code&gt; as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Change all occurences of &lt;code&gt;nvidia-current&lt;/code&gt; to &lt;code&gt;nvidia-352&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;After &lt;code&gt;Driver=&lt;/code&gt; insert &lt;code&gt;nvidia&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;After &lt;code&gt;KernelDriver=&lt;/code&gt; insert &lt;code&gt;nvidia-352&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;(if having trouble with optirun) uncomment the &lt;code&gt;BusID&lt;/code&gt; line and set it
  accordingly to what the comment above this line says.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Make sure that these lines are in &lt;code&gt;/etc/modprobe.d/bumblebee.conf&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;blacklist nvidia-352
blacklist nvidia-352-updates
blacklist nvidia-experimental-352

&lt;span class="nb"&gt;alias &lt;/span&gt;nvidia-uvm nvidia_352_uvm
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After &lt;code&gt;reboot&lt;/code&gt; everything should work fine. You can test it with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;optirun glxspheres64
&lt;span class="c"&gt;# compare the performance with default GPU running the command above without optirun&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you need more help: &lt;a href="http://developer.download.nvidia.com/compute/cuda/7.5/Prod/docs/sidebar/CUDA_Installation_Guide_Linux.pdf"&gt;CUDA installation guide for Linux&lt;/a&gt;&lt;/p&gt;</summary><category term="cuda"></category><category term="neural networks"></category></entry><entry><title>Setting up IPython with Git</title><link href="http://kele.github.io/cifar_recognition/setting-up-ipython-with-git.html" rel="alternate"></link><updated>2016-01-17T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-01-17:cifar_recognition/setting-up-ipython-with-git.html</id><summary type="html">&lt;p&gt;Since I've been annoyed by how IPython notebooks integrate with Git, I'd like
to share a solution for this problem.&lt;/p&gt;
&lt;p&gt;The description can be found here: &lt;a href="http://stackoverflow.com/a/25765194/1239545"&gt;http://stackoverflow.com/a/25765194/1239545&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;What it does is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it adds a hook for saving the notebook, which also saves a &lt;em&gt;pure&lt;/em&gt; version&lt;/li&gt;
&lt;li&gt;it suggests that you keep both the pure version and the notebook under version control&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>First post</title><link href="http://kele.github.io/cifar_recognition/first-post.html" rel="alternate"></link><updated>2016-01-16T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-01-16:cifar_recognition/first-post.html</id><summary type="html">&lt;p&gt;First post.&lt;/p&gt;</summary></entry></feed>